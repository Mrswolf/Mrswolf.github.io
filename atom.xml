<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>swolf&#39;s blog</title>
  
  <subtitle>记录我的学习生活</subtitle>
  <link href="https://mrswolf.github.io/atom.xml" rel="self"/>
  
  <link href="https://mrswolf.github.io/"/>
  <updated>2025-05-10T11:13:52.457Z</updated>
  <id>https://mrswolf.github.io/</id>
  
  <author>
    <name>swolf</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Dive into ESPIRiT, from Theory to Practice</title>
    <link href="https://mrswolf.github.io/espirit/"/>
    <id>https://mrswolf.github.io/espirit/</id>
    <published>2025-05-10T10:54:40.000Z</published>
    <updated>2025-05-10T11:13:52.457Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;This post summarizes the &lt;a href=&quot;https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.24751&quot;&gt;ESPIRiT&lt;/a&gt; algorithm for estimating coil sensitivies in MRI. It took me months to fully grasp the theory behind it.</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>cuda编程-矩阵乘法优化</title>
    <link href="https://mrswolf.github.io/learncuda1/"/>
    <id>https://mrswolf.github.io/learncuda1/</id>
    <published>2024-05-28T16:00:00.000Z</published>
    <updated>2024-06-22T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;上一篇blog实现了一个基本的cuda程序，本篇记录如何实现矩阵乘法并加速。</summary>
    
    
    
    <category term="cuda" scheme="https://mrswolf.github.io/categories/cuda/"/>
    
    
  </entry>
  
  <entry>
    <title>CMake Cheatsheet</title>
    <link href="https://mrswolf.github.io/learncmake/"/>
    <id>https://mrswolf.github.io/learncmake/</id>
    <published>2024-05-22T16:00:00.000Z</published>
    <updated>2024-06-23T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;CMake is a popular cross-platform build system that allows developers to use a common interface to define a set of rules to build the source code with different compilers, such as GCC, Clang and Visual Studio. In fact, CMake supports not only C/C++, but also other languages such as C# and Fortran. CMake is an essential tool for building software projects and making the whole process easier for anyone.</summary>
    
    
    
    <category term="c++" scheme="https://mrswolf.github.io/categories/c/"/>
    
    
  </entry>
  
  <entry>
    <title>cuda编程-基本概念</title>
    <link href="https://mrswolf.github.io/learncuda0/"/>
    <id>https://mrswolf.github.io/learncuda0/</id>
    <published>2024-05-17T16:00:00.000Z</published>
    <updated>2024-05-17T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;当今科学计算越来越复杂，各种模型越来越大，使用SVM做分类的时代早已一去不复返，通过GPU加速应用的重要性不言而喻。我在MRI领域工作的这几年，经常碰高度复杂的MRI应用，Matlab计算时间在几小时到几天不等，即使高度优化的C++的程序也需要10至30分钟左右。这些应用的CPU利用率已然接近100%，因此通过GPU进一步优化程序成为最可行的手段。</summary>
    
    
    
    <category term="cuda" scheme="https://mrswolf.github.io/categories/cuda/"/>
    
    
  </entry>
  
  <entry>
    <title>Powerful Bregman Methods</title>
    <link href="https://mrswolf.github.io/bregmanmethod/"/>
    <id>https://mrswolf.github.io/bregmanmethod/</id>
    <published>2024-05-05T16:00:00.000Z</published>
    <updated>2024-05-09T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;The Bregman method is an iterative method to solve convex optimization problems with equality constraints.</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Total Variation Denoising Problem</title>
    <link href="https://mrswolf.github.io/tvdenoise/"/>
    <id>https://mrswolf.github.io/tvdenoise/</id>
    <published>2024-05-04T16:00:00.000Z</published>
    <updated>2024-05-04T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Total variation (TV) denoising&lt;/strong&gt;, also known as TV regularization or TV filtering, is a powerful technique widely used in various fields, including medical imaging, computer vision, etc. It removes noises while preserving most important structural features. &lt;strong&gt;&lt;a href=&quot;https://www.ipam.ucla.edu/news/rudin-osher-fatemi-model-captures-infinity-and-beyond/&quot;&gt;The first image of black hole, captured by Event Horizon Telescope (EHT), was processed and revealed with this technique in 2019&lt;/a&gt;&lt;/strong&gt;.</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Tensor Decompositions</title>
    <link href="https://mrswolf.github.io/tensor-tricks/"/>
    <id>https://mrswolf.github.io/tensor-tricks/</id>
    <published>2024-05-03T15:30:49.000Z</published>
    <updated>2024-05-02T18:19:42.469Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;This post contains some userful tensor notation and tricks which I have seen and collected.</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/tags/machine-learning/"/>
    
    <category term="matrix decomposition" scheme="https://mrswolf.github.io/tags/matrix-decomposition/"/>
    
  </entry>
  
  <entry>
    <title>Preconditioned Conjugate Gradient Method</title>
    <link href="https://mrswolf.github.io/pcg/"/>
    <id>https://mrswolf.github.io/pcg/</id>
    <published>2024-04-05T16:00:00.000Z</published>
    <updated>2024-04-12T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;This weekend I learned &lt;strong&gt;Preconditioned Conjugate Gradient&lt;/strong&gt; method with Jonathan Richard Schewchuk’s lecture note &lt;a href=&quot;https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf&quot;&gt;“An Introduction to the Conjugate Gradient Method Without the Agonizing Path”&lt;/a&gt;. Here I document what I have learned from the note.&lt;/p&gt;</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>In-place Circshift</title>
    <link href="https://mrswolf.github.io/circshift/"/>
    <id>https://mrswolf.github.io/circshift/</id>
    <published>2024-03-24T16:00:00.000Z</published>
    <updated>2024-04-02T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;Last week I was attempting to implement an in-place &lt;code&gt;fftshift&lt;/code&gt; function in c++. I hoped this function could perform &lt;strong&gt;shifting along any given dimension of N-dimensional data&lt;/strong&gt;.</summary>
    
    
    
    <category term="algorithms" scheme="https://mrswolf.github.io/categories/algorithms/"/>
    
    
  </entry>
  
  <entry>
    <title>So How to Choose Tolerance for pinv?</title>
    <link href="https://mrswolf.github.io/pinv-tol/"/>
    <id>https://mrswolf.github.io/pinv-tol/</id>
    <published>2024-02-02T16:00:00.000Z</published>
    <updated>2024-02-02T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;The Moore-Penrose inverse or the pseudoinverse &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;A&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;&#92;mathbf{A}^+ &#92;in &#92;mathbb{R}^{n &#92;times m}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8104em;vertical-align:-0.0391em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathbf&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7713em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;∈&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.7713em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathbb&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7713em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathnormal mtight&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;×&lt;/span&gt;&lt;span class=&quot;mord mathnormal mtight&quot;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; of a matrix &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;A&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;&#92;mathbf{A} &#92;in &#92;mathbb{R}^{m &#92;times n}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.7252em;vertical-align:-0.0391em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathbf&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;∈&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.7713em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathbb&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7713em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathnormal mtight&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;×&lt;/span&gt;&lt;span class=&quot;mord mathnormal mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a kind of generalization of the inverse matrix to non-square matrices or ill-conditioned matricies. The most confusing part in coding a &lt;code&gt;pinv&lt;/code&gt; function is how to choose a appropriate tolerance truncating zero singular values.</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>How to Measure Memory Usage in C++</title>
    <link href="https://mrswolf.github.io/memory-usage-cpp/"/>
    <id>https://mrswolf.github.io/memory-usage-cpp/</id>
    <published>2024-01-24T16:00:00.000Z</published>
    <updated>2024-01-24T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;I’ve been struggling with calculating the memory usage for a week. Here’s the case: I got a program that needs to estimate how much memory it may consume during runtime with some predefined inputs, such as the size of images, etc. The problem is that the program is so complicated that nearly no one understands the code fully. Not to mention, there are lots of parallel codes in the program, scaling the memory usage by the dynamic number of threads.</summary>
    
    
    
    <category term="c++" scheme="https://mrswolf.github.io/categories/c/"/>
    
    
  </entry>
  
  <entry>
    <title>Build Modern C++ Projects in VSCode</title>
    <link href="https://mrswolf.github.io/vscode-cpp/"/>
    <id>https://mrswolf.github.io/vscode-cpp/</id>
    <published>2024-01-11T12:43:30.000Z</published>
    <updated>2024-01-12T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;I use Visual Studio when I work at the company. Visual Studio does provide a better coding experience on the Windows platform. But honestly, the majority of the coding at the company is just bug fixing, which is less enjoyable.</summary>
    
    
    
    <category term="tools" scheme="https://mrswolf.github.io/categories/tools/"/>
    
    
  </entry>
  
  <entry>
    <title>Robust Principle Component Analysis</title>
    <link href="https://mrswolf.github.io/rpca/"/>
    <id>https://mrswolf.github.io/rpca/</id>
    <published>2023-09-12T15:30:49.000Z</published>
    <updated>2024-05-12T05:02:50.621Z</updated>
    
    
      
      
    <summary type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;Background-of-PCA&quot;&gt;Background of PCA&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Principle component analysis (PCA)&lt;/strong&gt; is the most widely use</summary>
      
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Scientific Computing in VS Code</title>
    <link href="https://mrswolf.github.io/vscode-python/"/>
    <id>https://mrswolf.github.io/vscode-python/</id>
    <published>2023-06-11T12:23:45.000Z</published>
    <updated>2023-09-19T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;I used to do all scientific computing work on Jupyter notebooks. My most common way of debugging was print, which is definitely not the best way to do so.</summary>
    
    
    
    <category term="tools" scheme="https://mrswolf.github.io/categories/tools/"/>
    
    
  </entry>
  
  <entry>
    <title>Fourier Transform</title>
    <link href="https://mrswolf.github.io/fourier-transform/"/>
    <id>https://mrswolf.github.io/fourier-transform/</id>
    <published>2023-05-15T16:00:00.000Z</published>
    <updated>2024-03-25T12:24:05.418Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;The Fourier transform decomposes a function into different frequency components, which can be summed to represent the original function.</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Makefile使用规则</title>
    <link href="https://mrswolf.github.io/learn-makefile/"/>
    <id>https://mrswolf.github.io/learn-makefile/</id>
    <published>2022-06-06T16:00:00.000Z</published>
    <updated>2024-05-18T16:16:11.397Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;出于工作需要，我要开始系统学习c++了。目前我的主力台式机是Linux系统，最常用的编辑器是VS Code，所以想要得到一个比较完整的C/C++工程方案，似乎学习Makefile的相关规则是必不可少的。</summary>
    
    
    
    <category term="c++" scheme="https://mrswolf.github.io/categories/c/"/>
    
    
  </entry>
  
  <entry>
    <title>为什么要少用逆矩阵</title>
    <link href="https://mrswolf.github.io/why-not-invert-that-matrix/"/>
    <id>https://mrswolf.github.io/why-not-invert-that-matrix/</id>
    <published>2022-05-29T16:00:00.000Z</published>
    <updated>2022-06-01T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;我经常会在线性代数教材以及论坛讨论中看到不建议使用逆矩阵&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;A&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;&#92;mathbf{A}^{-1}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8141em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathbf&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8141em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;来求解线性方程&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;A&lt;/mi&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;&#92;mathbf{A}&#92;mathbf{x}=&#92;mathbf{b}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.6861em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathbf&quot;&gt;Ax&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.6944em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathbf&quot;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，尽管我一直遵循这样的原则（实践中逆矩阵确实不够稳定），但仍然不明白不使用逆矩阵的理由。本文总结了我在网上看到的一些关于逆矩阵的讨论，希望能解释为什么要少用逆矩阵来求解线性方程。&lt;/p&gt;</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>矩阵微积分</title>
    <link href="https://mrswolf.github.io/matrix-calculus/"/>
    <id>https://mrswolf.github.io/matrix-calculus/</id>
    <published>2022-03-27T16:00:00.000Z</published>
    <updated>2022-03-30T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;矩阵微分和矩阵求导几乎是求解优化问题不可避免的必学内容，这一方面的内容老实说我很难完全掌握。这里记录一下一些常用的矩阵微分求导的规范和技巧。</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>主成分分析PCA</title>
    <link href="https://mrswolf.github.io/principle-component-analysis/"/>
    <id>https://mrswolf.github.io/principle-component-analysis/</id>
    <published>2019-12-10T16:00:00.000Z</published>
    <updated>2022-03-20T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;主成分分析（Principle Component Analysis，PCA）是常用的一种矩阵分解算法，PCA通过旋转原始空间来使得数据在各个正交轴上的投影最大，通过选择前几个正交轴可以实现数据降维的目的。</summary>
    
    
    
    <category term="machine learning" scheme="https://mrswolf.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>manjaro踩坑记(2022更新版)</title>
    <link href="https://mrswolf.github.io/my-manjaro-log/"/>
    <id>https://mrswolf.github.io/my-manjaro-log/</id>
    <published>2019-05-23T16:00:00.000Z</published>
    <updated>2022-03-20T16:00:00.000Z</updated>
    
    
    <summary type="html">&lt;!-- toc --&gt;
&lt;p&gt;从2019年到2022年，manjaro发行版渡过了我的整个博士生涯。最近毕业重新装了系统，依然选择了最新的&lt;a href=&quot;https://manjaro.org/downloads/official/kde/&quot;&gt;manjaro KDE Plasma 21.2.4&lt;/a&gt;（本来装了arch，大小问题不断被劝退了😜）。基本上这台linux主机要跟着我进入人生下一阶段，作为主力台式机也不打算再折腾了。安装过程中有一些新的学习体会（坑），在这里更新记录一下，希望能帮到有需要的朋友～</summary>
    
    
    
    <category term="linux" scheme="https://mrswolf.github.io/categories/linux/"/>
    
    
  </entry>
  
</feed>
